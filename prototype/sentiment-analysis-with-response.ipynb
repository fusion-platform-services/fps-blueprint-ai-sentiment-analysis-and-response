{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Analyzer of Customer Reviews\n",
    "\n",
    "This example illustrates core function of analyzing customer reviews using AI and generating a response when needed.\n",
    "\n",
    "This example illustrate the following:\n",
    "- Determine the sentiment of a review (positive, neutral, negative).\n",
    "- For negative reviews, extract information from the review to classify the cause (common themes and keywords).\n",
    "- Identify whether a response is required back to the customer.\n",
    "- Generate a response mentioning alternative products that may satisfy the customer.\n",
    "- Control the accuracy of sentiment analysis. Target >90%.\n",
    "- Visualize insights.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "!pip install pandas openai matplotlib wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import gzip\n",
    "import json\n",
    "import requests\n",
    "from wordcloud import WordCloud\n",
    "from openai import OpenAI\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Constants\n",
    "SAMPLE_SIZE = 2 # Number of products (parent_asin) to sample\n",
    "MIN_NUM_OF_REVIEWS = 10 # minimum number of reviews for a product to be considered\n",
    "\n",
    "# Set OpenAI API key\n",
    "openai_api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Dataset URL and local file path\n",
    "review_dataset_url = \"https://datarepo.eng.ucsd.edu/mcauley_group/data/amazon_2023/raw/review_categories/Amazon_Fashion.jsonl.gz\"\n",
    "metadata_dataset_url = \"https://datarepo.eng.ucsd.edu/mcauley_group/data/amazon_2023/raw/meta_categories/meta_Amazon_Fashion.jsonl.gz\"\n",
    "review_local_file_path = \"Amazon_Fashion.jsonl.gz\"\n",
    "metadata_local_file_path = \"meta_Amazon_Fashion.jsonl.gz\"\n",
    "\n",
    "print('----------------------------------------------------')\n",
    "print('Download and Load Data')\n",
    "print('----------------------------------------------------')\n",
    "\n",
    "def download_dataset(url, local_file):\n",
    "    print(\"Downloading dataset...\")\n",
    "    response = requests.get(url, stream=True)\n",
    "    with open(local_file, 'wb') as f:\n",
    "        for chunk in response.iter_content(chunk_size=1024):\n",
    "            if chunk:\n",
    "                f.write(chunk)\n",
    "    print(\"Download complete.\")\n",
    "\n",
    "def load_data(file_path):\n",
    "    print(\"Loading the dataset...\")\n",
    "    with gzip.open(file_path, 'rt', encoding='utf-8') as f:\n",
    "        data = [json.loads(line) for line in f]\n",
    "    print(\"Loading complete.\")\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Check if the reviews file already exists other wise download\n",
    "if not os.path.exists(review_local_file_path):\n",
    "    download_dataset(review_dataset_url, review_local_file_path)\n",
    "else:\n",
    "    print(\"Review file already exists. Skipping download.\")\n",
    "\n",
    "# Load the data\n",
    "df = load_data(review_local_file_path)\n",
    "print(f\"Loaded reviews dataset with {len(df)} rows.\")\n",
    "\n",
    "\n",
    "# Check if the metadata file already exists other wise download\n",
    "if not os.path.exists(metadata_local_file_path):\n",
    "    download_dataset(metadata_dataset_url, metadata_local_file_path)\n",
    "else:\n",
    "    print(\"Metadata file already exists. Skipping download.\")\n",
    "\n",
    "# load metadata\n",
    "df_metadata = load_data(metadata_local_file_path)\n",
    "print(f\"Loaded metadata dataset with {len(df_metadata)} rows.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('----------------------------------------------------')\n",
    "print('Prepare sampled dataset')\n",
    "print('----------------------------------------------------')\n",
    "\n",
    "# Create a new column 'review' that combines 'rating', 'title', and 'text'\n",
    "df.loc[:, 'review'] = df.apply(lambda row: f\"Rating: {row['rating']}; Title: {row['title']}; Text: {row['text']}\", axis=1)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "df1 = df[['review', 'parent_asin']]\n",
    "\n",
    "# keep only the columns we need\n",
    "df_metadata = df_metadata[['parent_asin', 'store', 'title']].drop_duplicates()\n",
    "\n",
    "# merge the metadata with the reviews based on parent_asin\n",
    "df1 = df1.merge(df_metadata, left_on='parent_asin', right_on='parent_asin', how='inner')\n",
    "\n",
    "# Group by 'parent_asin' and calculate the quantity per each\n",
    "selected_asins = df1.groupby('parent_asin').size().reset_index(name='review_qty')\n",
    "\n",
    "# Filter out rows where quantity is less than 10\n",
    "selected_asins = selected_asins[selected_asins['review_qty'] > MIN_NUM_OF_REVIEWS].sample(n=SAMPLE_SIZE, random_state=1)\n",
    "\n",
    "# Filter the original dataframe to include only records with parent_asin in selected_asins\n",
    "df_sampled = df1[df1['parent_asin'].isin(selected_asins['parent_asin'])]\n",
    "\n",
    "# Drop unnecessary columns\n",
    "df_sampled = df_sampled[['parent_asin', 'store', 'review', 'title']]\n",
    "display(df_sampled.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('----------------------------------------------------')\n",
    "print(\"Analyze sentiment using OpenAI API...\")\n",
    "print('----------------------------------------------------')\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = OpenAI(\n",
    "    api_key=openai_api_key\n",
    ")\n",
    "\n",
    "def analyze_sentiment(text):\n",
    "    prompt = '''\n",
    "    Analyze the customer review based on the following three criteria: \n",
    "    - sentiment: could be 'Positive', 'Neutral', or 'Negative'.\n",
    "    - theme: generalize key words from the review.\n",
    "    - response: only for negative reviews write a response to the customer. Offer free shipping as needed. For extreme cases offer 5%% discount coupon for the next purchase in the store.\n",
    "\n",
    "    Write output as a JSON formatted string.\n",
    "\n",
    "    User Review: \n",
    "    '''\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant in the fashion online store.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"{prompt} \\\"{text}\\\"\"}\n",
    "    ]\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3o-mini\",\n",
    "        messages=messages,\n",
    "        max_tokens=100,  # Limit the response to the classification only\n",
    "        temperature=0,  # Make the response deterministic\n",
    "        response_format={ \"type\": \"json_object\" }\n",
    "    )\n",
    "    print('.', end='')\n",
    "    return response.choices[0].message.content.strip()\n",
    "    \n",
    "\n",
    "# Apply sentiment analysis to the first 100 reviews\n",
    "print(f\"Analyzing sentiment for {SAMPLE_SIZE} items...\")\n",
    "\n",
    "ai_response = df_sampled['review'].apply(lambda x: analyze_sentiment(x))\n",
    "\n",
    "print(\"\\nSentiment analysis complete.\")\n",
    "\n",
    "\n",
    "def safe_json_loads(x):\n",
    "\ttry:\n",
    "\t\treturn json.loads(x)\n",
    "\texcept json.JSONDecodeError:\n",
    "\t\treturn {}\n",
    "\n",
    "df_sampled['sentiment'] = ai_response.apply(lambda x: safe_json_loads(x).get('sentiment', 'Unknown'))\n",
    "df_sampled['theme'] = ai_response.apply(lambda x: safe_json_loads(x).get('theme', 'Unknown'))\n",
    "df_sampled['response'] = ai_response.apply(lambda x: safe_json_loads(x).get('response', 'Unknown'))\n",
    "\n",
    "# Display the first few rows with sentiment\n",
    "df_sampled.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('----------------------------------------------------')\n",
    "print(\"Generating visualizations...\")\n",
    "print('----------------------------------------------------')\n",
    "\n",
    "# Sentiment distribution\n",
    "plt.figure(figsize=(8, 5))\n",
    "df_sampled['sentiment'].value_counts().plot(kind='pie', wedgeprops=dict(width=0.6))\n",
    "plt.title(f\"Sentiment Distribution\")\n",
    "plt.xlabel(\"Sentiment\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n",
    "\n",
    "df_positive = df_sampled[df_sampled['sentiment'] == 'Positive']\n",
    "df_negative = df_sampled[df_sampled['sentiment'] == 'Negative']\n",
    "\n",
    "# Word cloud for common positive themes\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(\n",
    "    \" \".join([keyword for keywords in df_positive['theme'] for keyword in keywords])\n",
    ")\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.title(f\"Common Themes in Positive Reviews\")\n",
    "plt.show()\n",
    "\n",
    "# Word cloud for common negative themes\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(\n",
    "    \" \".join([keyword for keywords in df_negative['theme'] for keyword in keywords])\n",
    ")\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.title(f\"Common Themes in Negative Reviews\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print('Negative Reviews:')\n",
    "df_negative[['title', 'review', 'response']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Review: ', df_negative.iloc[0]['review'])\n",
    "print('Response: ', df_negative.iloc[0]['response'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
